[
  {
    "objectID": "03_labour_main.html",
    "href": "03_labour_main.html",
    "title": "Track Canada’s Labour Statistics",
    "section": "",
    "text": "Font name: `Playfair Display`\nFont name: `Lato`"
  },
  {
    "objectID": "03_labour_main.html#parameters",
    "href": "03_labour_main.html#parameters",
    "title": "Track Canada’s Labour Statistics",
    "section": "",
    "text": "Font name: `Playfair Display`\nFont name: `Lato`"
  },
  {
    "objectID": "02_develop_visualization.html",
    "href": "02_develop_visualization.html",
    "title": "Developing the employment heatmap visualization",
    "section": "",
    "text": "from pyprojroot import here\n\n\nLABOUR_DATA_FILE = here() / \"data\" / \"14100355.csv\"\nFIGURE_THEME_SIZE = (8, 6)\nFILTER_YEAR = (2018, 2025)\n\n\n\n\n\nimport polars as pl\nimport polars.selectors as cs\nfrom mizani.bounds import squish\nimport mizani.labels as ml\nimport mizani.breaks as mb\nimport textwrap\nfrom pyprojroot import here\nfrom great_tables import GT, md, html\nfrom plotnine import *\nfrom labourcan.data_processing import read_labourcan,calculate_centered_rank\n\n\n\n\nread_labourcan returns a polars with:\n\nUnused columns removed\nFiltered to seasonally adjusted estimates only\nFiltered to Canada level estimates\nAdditional YEAR, MONTH, and DATE_YMD columns extracted from REF_DATE\nSorted chronologically by year and month\n\nSee labour.qmd for details on data processing.\n\nlabour = read_labourcan(LABOUR_DATA_FILE)\nlabour_processed = calculate_centered_rank(labour)",
    "crumbs": [
      "Developing the employment heatmap visualization"
    ]
  },
  {
    "objectID": "02_develop_visualization.html#parameters",
    "href": "02_develop_visualization.html#parameters",
    "title": "Developing the employment heatmap visualization",
    "section": "",
    "text": "from pyprojroot import here\n\n\nLABOUR_DATA_FILE = here() / \"data\" / \"14100355.csv\"\nFIGURE_THEME_SIZE = (8, 6)\nFILTER_YEAR = (2018, 2025)",
    "crumbs": [
      "Developing the employment heatmap visualization"
    ]
  },
  {
    "objectID": "02_develop_visualization.html#libraries",
    "href": "02_develop_visualization.html#libraries",
    "title": "Developing the employment heatmap visualization",
    "section": "",
    "text": "import polars as pl\nimport polars.selectors as cs\nfrom mizani.bounds import squish\nimport mizani.labels as ml\nimport mizani.breaks as mb\nimport textwrap\nfrom pyprojroot import here\nfrom great_tables import GT, md, html\nfrom plotnine import *\nfrom labourcan.data_processing import read_labourcan,calculate_centered_rank",
    "crumbs": [
      "Developing the employment heatmap visualization"
    ]
  },
  {
    "objectID": "02_develop_visualization.html#read-data",
    "href": "02_develop_visualization.html#read-data",
    "title": "Developing the employment heatmap visualization",
    "section": "",
    "text": "read_labourcan returns a polars with:\n\nUnused columns removed\nFiltered to seasonally adjusted estimates only\nFiltered to Canada level estimates\nAdditional YEAR, MONTH, and DATE_YMD columns extracted from REF_DATE\nSorted chronologically by year and month\n\nSee labour.qmd for details on data processing.\n\nlabour = read_labourcan(LABOUR_DATA_FILE)\nlabour_processed = calculate_centered_rank(labour)",
    "crumbs": [
      "Developing the employment heatmap visualization"
    ]
  },
  {
    "objectID": "02_develop_visualization.html#geom_point-or-geom_tile",
    "href": "02_develop_visualization.html#geom_point-or-geom_tile",
    "title": "Developing the employment heatmap visualization",
    "section": "geom_point or geom_tile",
    "text": "geom_point or geom_tile\nIt looks good. but the whitespace between each point is distracting. I could make the point size larger, but the ratio of point size to range of the x and y axis, as well as the figure size all will determine ultimately how much whitespace remains between each point.\nWe can use geom_tile instead, which will plot rectangles specified by a center point.\n\nlabour_processed_cat = labour_processed.drop_nulls(\n    ['centered_rank_across_industry'])\norder = (\n    labour_processed_cat.select('centered_rank_across_industry').unique().sort(\n        'centered_rank_across_industry')\n    .to_series()\n    .cast(pl.Utf8)\n    .to_list()\n)\n\nlabour_processed_cat = (\n    labour_processed_cat.with_columns(\n        pl.col('centered_rank_across_industry').cast(\n            pl.Utf8).cast(pl.Enum(categories=order)).alias('centered_rank_cat')\n    )\n)\n\n(\n    ggplot((\n        labour_processed_cat.filter(\n            pl.col(\"YEAR\") &gt;= FILTER_YEAR[0],\n            pl.col(\"YEAR\") &lt;= FILTER_YEAR[1]\n        )\n    ), aes(x=\"DATE_YMD\", y=\"centered_rank_across_industry\", fill=\"PDIFF\"))\n    + geom_tile(height=0.95)  # whitespace between tiles, vertically\n    + theme_tufte()\n    + theme(\n        figure_size=FIGURE_THEME_SIZE,\n        axis_text_x=element_text(angle=90)\n    )\n    + scale_fill_gradient2(\n        limits=(-0.01, 0.01), low=\"#ff0000ff\", high=\"#0000dbff\", midpoint=0, oob=squish)\n\n)\n\n\n\n\n\n\n\n\nThis is looking pretty good. I added height = 0.95 to add some whitespace between tiles vertically. I actually wanted to remove whitespace completely, but I discovered width for geom_tile doesn’t work the same as it does for ggplot2. If I set width=1 it seems to make the tiles smaller, instead of wider.",
    "crumbs": [
      "Developing the employment heatmap visualization"
    ]
  },
  {
    "objectID": "02_develop_visualization.html#explicit-color-mapping-with-scale_color_manual",
    "href": "02_develop_visualization.html#explicit-color-mapping-with-scale_color_manual",
    "title": "Developing the employment heatmap visualization",
    "section": "Explicit color mapping with scale_color_manual",
    "text": "Explicit color mapping with scale_color_manual\nI am fairly happy with the scale_fill_gradient2 used with squish. We get a really nice palette that’s centered around 0. However scale_fill_gradient2 is limited to 3 colors (high, midpoint, low), which is not quite enable the more dynamic color palette that I’m seeking.\nTo be more explicit with the colors, I will bin the PDIFF and map colors manually using scale_fill_manual\n\nBin with polars.Series.cut\n\nlabour_processed_cutted = (\n    labour_processed_cat.with_columns(\n        pl.col(\"PDIFF\")\n        .cut(\n            [\n                -0.05,\n                -0.025,\n                -0.012,\n                -0.0080,\n                -0.0040,\n                0,\n                0.0040,\n                0.0080,\n                0.012,\n                0.025,\n                0.05,\n            ]\n        )\n        .alias(\"PDIFF_BINNED\")\n    )\n    .with_columns(\n        pl.when(pl.col(\"PDIFF\") == 0)\n        .then(pl.lit(\"0\"))\n        .otherwise(pl.col(\"PDIFF_BINNED\"))\n        .alias(\"PDIFF_BINNED\")\n    )\n    .sort(\"PDIFF\")\n    .with_columns(pl.col(\"PDIFF_BINNED\"))\n)\nlabour_processed_cutted.group_by(\"PDIFF_BINNED\").len()\n\n\nshape: (13, 2)\n\n\n\nPDIFF_BINNED\nlen\n\n\ncat\nu32\n\n\n\n\n\"(0, 0.004]\"\n2624\n\n\n\"(-0.025, -0.012]\"\n892\n\n\n\"(-inf, -0.05]\"\n47\n\n\n\"(-0.012, -0.008]\"\n717\n\n\n\"(0.05, inf]\"\n58\n\n\n…\n…\n\n\n\"0\"\n74\n\n\n\"(-0.05, -0.025]\"\n255\n\n\n\"(0.008, 0.012]\"\n1021\n\n\n\"(-0.004, 0]\"\n1999\n\n\n\"(0.012, 0.025]\"\n1292\n\n\n\n\n\n\n\n(\n    ggplot(\n        (\n            labour_processed_cutted.filter(\n                pl.col(\"YEAR\") &gt;= FILTER_YEAR[0], pl.col(\"YEAR\") &lt;= FILTER_YEAR[1]\n            )\n        ),\n        aes(x=\"DATE_YMD\", y=\"centered_rank_cat\", fill=\"PDIFF_BINNED\"),\n    )\n    + geom_tile(height=0.95)  # whitespace between tiles, vertically\n    + theme_tufte()\n    + theme(figure_size=FIGURE_THEME_SIZE, axis_text_x=element_text(angle=90))\n)\n\n\n\n\n\n\n\n\n\n\nscale_fill_manual for explicit color mapping\nNow we need to order the levels, and map explicit colors\nWe will make PDIFF=0% to be gray, positive values to have a green and blue colors (job growth = good), and negative values to have warmer (alarming, bad) colors.\n\norder = (\n    labour_processed_cutted.drop_nulls()\n    .sort(\"PDIFF\")\n    .select(pl.col(\"PDIFF_BINNED\"))\n    .unique(maintain_order=True)\n    .to_series()\n    .to_list()\n)\n\nlabour_processed_cutted_ordered = labour_processed_cutted.with_columns(\n    pl.col(\"PDIFF_BINNED\").cast(pl.Enum(order))\n)\n\ncolor_mapping = {\n    \"(-inf, -0.05]\": \"#d82828ff\",\n    \"(-0.05, -0.025]\": \"#fa6f1fff\",\n    \"(-0.025, -0.012]\": \"#f1874aff\",\n    \"(-0.012, -0.008]\": \"#f1b274ff\",\n    \"(-0.008, -0.004]\": \"#FEE08B\",\n    \"(-0.004, 0]\": \"#FFFFBF\",\n    \"0\": \"#a8a8a8ff\",\n    \"(0, 0.004]\": \"#E6F5D0\",\n    \"(0.004, 0.008]\": \"#bce091ff\",\n    \"(0.008, 0.012]\": \"#9ad65fff\",\n    \"(0.012, 0.025]\": \"#78b552ff\",\n    \"(0.025, 0.05]\": \"#5cb027ff\",\n    \"(0.05, inf]\": \"#1f6fc6ff\",\n}\n\n(\n    ggplot(\n        (\n            labour_processed_cutted.filter(\n                pl.col(\"YEAR\") &gt;= FILTER_YEAR[0], pl.col(\"YEAR\") &lt;= FILTER_YEAR[1]\n            )\n        ),\n        aes(x=\"DATE_YMD\", y=\"centered_rank_across_industry\", fill=\"PDIFF_BINNED\"),\n    )\n    + geom_tile(color=\"white\")\n    # + geom_point(shape=\"s\")\n    + theme_tufte()\n    + theme(figure_size=FIGURE_THEME_SIZE, axis_text_x=element_text(angle=90))\n    + scale_fill_manual(values=color_mapping, breaks=order)\n)\n\n\n\n\n\n\n\n\nThat looks great. The power of scale_fill_manual enables much more control over the color palette. However, the cost was that it takes a lot more effort and lines of code to create a custom mapping.",
    "crumbs": [
      "Developing the employment heatmap visualization"
    ]
  },
  {
    "objectID": "02_develop_visualization.html#the-legend",
    "href": "02_develop_visualization.html#the-legend",
    "title": "Developing the employment heatmap visualization",
    "section": "The legend",
    "text": "The legend\n…is extremely accurate, however we are going to simplify it and nicer to look at.\nFirst let’s make the text more concise: we don’t need every bin to be labelled, and instead of listing the range, we can just describe the midpoint.\n\nlegend_labels = [\n    \"-5%\",  # the ends can be labelled with the boundary e.g. implies &lt;-5%\n    \"\",\n    \"\",\n    \"-1%\",\n    \"\",\n    \"\",\n    \"No change\",\n    \"\",\n    \"\",\n    \"\",\n    \"1%\",\n    \"\",\n    \"5%\",\n]\n\n(\n    ggplot(\n        labour_processed_cutted.filter(\n            pl.col(\"YEAR\") &gt;= FILTER_YEAR[0], pl.col(\"YEAR\") &lt;= FILTER_YEAR[1]\n        ),\n        aes(x=\"DATE_YMD\", y=\"centered_rank_across_industry\", fill=\"PDIFF_BINNED\"),\n    )\n    + geom_tile(color=\"white\")\n    + theme_tufte()\n    + theme(\n        figure_size=FIGURE_THEME_SIZE,\n        axis_text_x=element_text(angle=90),\n        legend_justification_right=1,\n        legend_position=\"right\",\n        legend_text_position=\"right\",\n        legend_title=element_blank(),\n        legend_key_spacing=0,\n        legend_key_width=10,\n        legend_key_height=10,\n        legend_text=element_text(size=8),\n    )\n    + scale_fill_manual(values=color_mapping, breaks=order, labels=legend_labels)\n)\n\n\n\n\n\n\n\n\nLooks much better than my first attempt with a horizontal legend",
    "crumbs": [
      "Developing the employment heatmap visualization"
    ]
  },
  {
    "objectID": "02_develop_visualization.html#text-and-fonts",
    "href": "02_develop_visualization.html#text-and-fonts",
    "title": "Developing the employment heatmap visualization",
    "section": "Text and fonts",
    "text": "Text and fonts\nNext up is the text and fonts. I played with a few fonts on google fonts before settling on two.\nFirst, install the fonts:\n\nFONT_PRIMARY = \"Playfair Display\"\nFONT_SECONDARY = \"Lato\"\nimport mpl_fontkit as fk\nfk.install(FONT_PRIMARY)\nfk.install(FONT_SECONDARY)\n\nFont name: `Playfair Display`\nFont name: `Lato`\n\n\nplotnine breaks and labels for the scales can be easily adjusted using mizani, which is like the scales equivalent to ggplot2\nWe’re going to use mizani.breaks.breaks_date_width to put breaks for each year, and mizani.labels.label_date to drop the “month” part of the date.\n\nimport mizani.labels as ml\nimport mizani.breaks as mb\n\nplot = (\n    ggplot(\n        labour_processed_cutted.filter(\n            pl.col(\"YEAR\") &gt;= FILTER_YEAR[0], pl.col(\"YEAR\") &lt;= FILTER_YEAR[1]\n        ),\n        aes(x=\"DATE_YMD\", y=\"centered_rank_across_industry\", fill=\"PDIFF_BINNED\"),\n    )\n    + geom_tile(color=\"white\", height=0.95)\n    + theme_tufte()\n    + theme(\n        text=element_text(family=FONT_PRIMARY),\n        figure_size=FIGURE_THEME_SIZE,\n        axis_text_y=element_text(family=FONT_SECONDARY),\n        axis_text_x=element_text(family=FONT_SECONDARY),\n        axis_title_y=element_text(weight=300),\n        legend_justification_right=1,\n        legend_position=\"right\",\n        legend_text_position=\"right\",\n        legend_title_position=\"top\",\n        legend_key_spacing=0,\n        legend_key_width=15,\n        legend_key_height=15,\n        legend_text=element_text(size=8, family=FONT_SECONDARY),\n        legend_title=element_blank(),\n        plot_title=element_text(ha=\"left\"),\n        plot_subtitle=element_text(\n            ha=\"left\", margin={\"b\": 1, \"units\": \"lines\"}),\n    )\n    + scale_fill_manual(values=color_mapping,\n                        breaks=order, labels=legend_labels)\n    + guides(fill=guide_legend(ncol=1, reverse=True))\n    + scale_x_datetime(\n        labels=ml.label_date(\"%Y\"),  # Format labels to show only the year\n        expand=(0, 0),\n        breaks=mb.breaks_date_width(\"1 years\"),\n    )\n    + labs(\n        title=\"Sector Shifts: Where Canada's Jobs Are Moving\",\n        subtitle=textwrap.fill(\n            \"Track the number of industries gaining or losing jobs each month. Boxes are shaded based on percentage change from previous month in each industry's employment levels.\",\n            width=75,\n        ),\n        x=\"\",\n        y=\"&lt; SECTORS FALLING            SECTORS RISING &gt;\",\n    )\n)\nplot",
    "crumbs": [
      "Developing the employment heatmap visualization"
    ]
  },
  {
    "objectID": "02_develop_visualization.html#highlighting-an-industry",
    "href": "02_develop_visualization.html#highlighting-an-industry",
    "title": "Developing the employment heatmap visualization",
    "section": "Highlighting an Industry",
    "text": "Highlighting an Industry\nFor more deeper insights, I would like to see where each individual ranks in the graphic.\n\nlabour_processed_cutted.select('Industry').unique().to_series().to_list()\nINDUSTRY = 'Wholesale and retail trade [41, 44-45]'\n\nplot_data_subsetted = labour_processed_cutted.filter(\n    pl.col(\"YEAR\") &gt;= FILTER_YEAR[0],\n    pl.col(\"YEAR\") &lt;= FILTER_YEAR[1],\n    pl.col('Industry') == INDUSTRY\n)\n(\n    plot\n    + geom_point(data=plot_data_subsetted, color='black', fill='black')\n)",
    "crumbs": [
      "Developing the employment heatmap visualization"
    ]
  },
  {
    "objectID": "02_develop_visualization.html#things-that-didnt-work",
    "href": "02_develop_visualization.html#things-that-didnt-work",
    "title": "Developing the employment heatmap visualization",
    "section": "Things that didn’t work",
    "text": "Things that didn’t work\nThis section is a non-exhaustive list of design elements I wasn’t able to solve with plotnine\n\nHorizontal legend with horizontal legend text\nInitially I wanted a horizontal legend for the colors. But in order to remove the whitespace between keys, I discovered that the text needs to be smaller than the legend keys, otherwise they “push” the legend keys apart in uneven manner. I attempted to (unsuccesfully) address this by making the legend text small, eliminating as much text as possible (e.g. removing the “%” characters for -0.50 and 0.50), and lastly increasing the legend key size.\nBut it still didn’t really work out the way I hoped, so I stuck with a vertical legend instead.",
    "crumbs": [
      "Developing the employment heatmap visualization"
    ]
  },
  {
    "objectID": "01_develop_data_processing.html",
    "href": "01_develop_data_processing.html",
    "title": "Processing StatCan Data",
    "section": "",
    "text": "from pyprojroot import here\n\n\nLABOUR_DATA_FILE = here() / \"data\" / \"14100355.csv\"\n\n\n\n\n\nimport polars as pl\nimport polars.selectors as cs\nfrom mizani.bounds import squish\nfrom pyprojroot import here\nfrom great_tables import GT, md, html\nfrom plotnine import *\nfrom labourcan.data_processing import read_labourcan\n\n\n\n\nread_labourcan returns a polars dataframe with columns:\n\nUnnecessary metadata columns removed\nFiltered to seasonally adjusted estimates only\nAdditional YEAR, MONTH, and DATE_YMD columns extracted from REF_DATE\nSorted chronologically by year and month\n\n\nlabour = read_labourcan(LABOUR_DATA_FILE)\nlabour.glimpse()\n\nRows: 12252\nColumns: 10\n$ REF_DATE    &lt;str&gt; '1976-01', '1976-01', '1976-01', '1976-01', '1976-01', '1976-01', '1976-01', '1976-01', '1976-01', '1976-01'\n$ GEO         &lt;str&gt; 'Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'Canada'\n$ Industry    &lt;str&gt; 'Total employed, all industries', 'Goods-producing sector', 'Agriculture [111-112, 1100, 1151-1152]', 'Forestry, fishing, mining, quarrying, oil and gas [21, 113-114, 1153, 2100]', 'Utilities [22]', 'Construction [23]', 'Manufacturing [31-33]', 'Services-producing sector', 'Wholesale and retail trade [41, 44-45]', 'Transportation and warehousing [48-49]'\n$ Statistics  &lt;str&gt; 'Estimate', 'Estimate', 'Estimate', 'Estimate', 'Estimate', 'Estimate', 'Estimate', 'Estimate', 'Estimate', 'Estimate'\n$ Data type   &lt;str&gt; 'Seasonally adjusted', 'Seasonally adjusted', 'Seasonally adjusted', 'Seasonally adjusted', 'Seasonally adjusted', 'Seasonally adjusted', 'Seasonally adjusted', 'Seasonally adjusted', 'Seasonally adjusted', 'Seasonally adjusted'\n$ UOM         &lt;str&gt; 'Persons in thousands', 'Persons in thousands', 'Persons in thousands', 'Persons in thousands', 'Persons in thousands', 'Persons in thousands', 'Persons in thousands', 'Persons in thousands', 'Persons in thousands', 'Persons in thousands'\n$ VALUE       &lt;f64&gt; 9636.7, 3312.5, 463.6, 244.2, 110.4, 654.9, 1839.5, 6324.1, 1592.9, 573.2\n$ YEAR        &lt;i32&gt; 1976, 1976, 1976, 1976, 1976, 1976, 1976, 1976, 1976, 1976\n$ MONTH       &lt;i32&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n$ DATE_YMD   &lt;date&gt; 1976-01-01, 1976-01-01, 1976-01-01, 1976-01-01, 1976-01-01, 1976-01-01, 1976-01-01, 1976-01-01, 1976-01-01, 1976-01-01",
    "crumbs": [
      "Processing StatCan Data"
    ]
  },
  {
    "objectID": "01_develop_data_processing.html#parameters",
    "href": "01_develop_data_processing.html#parameters",
    "title": "Processing StatCan Data",
    "section": "",
    "text": "from pyprojroot import here\n\n\nLABOUR_DATA_FILE = here() / \"data\" / \"14100355.csv\"",
    "crumbs": [
      "Processing StatCan Data"
    ]
  },
  {
    "objectID": "01_develop_data_processing.html#libraries",
    "href": "01_develop_data_processing.html#libraries",
    "title": "Processing StatCan Data",
    "section": "",
    "text": "import polars as pl\nimport polars.selectors as cs\nfrom mizani.bounds import squish\nfrom pyprojroot import here\nfrom great_tables import GT, md, html\nfrom plotnine import *\nfrom labourcan.data_processing import read_labourcan",
    "crumbs": [
      "Processing StatCan Data"
    ]
  },
  {
    "objectID": "01_develop_data_processing.html#read-data",
    "href": "01_develop_data_processing.html#read-data",
    "title": "Processing StatCan Data",
    "section": "",
    "text": "read_labourcan returns a polars dataframe with columns:\n\nUnnecessary metadata columns removed\nFiltered to seasonally adjusted estimates only\nAdditional YEAR, MONTH, and DATE_YMD columns extracted from REF_DATE\nSorted chronologically by year and month\n\n\nlabour = read_labourcan(LABOUR_DATA_FILE)\nlabour.glimpse()\n\nRows: 12252\nColumns: 10\n$ REF_DATE    &lt;str&gt; '1976-01', '1976-01', '1976-01', '1976-01', '1976-01', '1976-01', '1976-01', '1976-01', '1976-01', '1976-01'\n$ GEO         &lt;str&gt; 'Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'Canada', 'Canada'\n$ Industry    &lt;str&gt; 'Total employed, all industries', 'Goods-producing sector', 'Agriculture [111-112, 1100, 1151-1152]', 'Forestry, fishing, mining, quarrying, oil and gas [21, 113-114, 1153, 2100]', 'Utilities [22]', 'Construction [23]', 'Manufacturing [31-33]', 'Services-producing sector', 'Wholesale and retail trade [41, 44-45]', 'Transportation and warehousing [48-49]'\n$ Statistics  &lt;str&gt; 'Estimate', 'Estimate', 'Estimate', 'Estimate', 'Estimate', 'Estimate', 'Estimate', 'Estimate', 'Estimate', 'Estimate'\n$ Data type   &lt;str&gt; 'Seasonally adjusted', 'Seasonally adjusted', 'Seasonally adjusted', 'Seasonally adjusted', 'Seasonally adjusted', 'Seasonally adjusted', 'Seasonally adjusted', 'Seasonally adjusted', 'Seasonally adjusted', 'Seasonally adjusted'\n$ UOM         &lt;str&gt; 'Persons in thousands', 'Persons in thousands', 'Persons in thousands', 'Persons in thousands', 'Persons in thousands', 'Persons in thousands', 'Persons in thousands', 'Persons in thousands', 'Persons in thousands', 'Persons in thousands'\n$ VALUE       &lt;f64&gt; 9636.7, 3312.5, 463.6, 244.2, 110.4, 654.9, 1839.5, 6324.1, 1592.9, 573.2\n$ YEAR        &lt;i32&gt; 1976, 1976, 1976, 1976, 1976, 1976, 1976, 1976, 1976, 1976\n$ MONTH       &lt;i32&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n$ DATE_YMD   &lt;date&gt; 1976-01-01, 1976-01-01, 1976-01-01, 1976-01-01, 1976-01-01, 1976-01-01, 1976-01-01, 1976-01-01, 1976-01-01, 1976-01-01",
    "crumbs": [
      "Processing StatCan Data"
    ]
  },
  {
    "objectID": "01_develop_data_processing.html#change-per-month",
    "href": "01_develop_data_processing.html#change-per-month",
    "title": "Processing StatCan Data",
    "section": "% Change per month",
    "text": "% Change per month\nFirst, compute % change from previous month. This needs to be done over different subsets of data:\n\nIndustry\nGeolocation\nLabour Force Characteristic (If provided)\nGender\nAge group\n\nIn the seasonally adjusted dataset, only Industry and Geolocation are provided. The LFC is total employment, the Gender is both, and Age group is all.\n\nlabour_processed = (\n    # if we sort acesnding by time, then lag value is the month before\n    labour.sort([\"Industry\", \"YEAR\", \"MONTH\"])\n    .with_columns(\n        LAGGED_VALUE=pl.col(\"VALUE\")\n        .shift(1)\n        .over([\"Industry\"])\n    )\n    # compute percent difference\n    .with_columns((pl.col(\"VALUE\") - pl.col(\"LAGGED_VALUE\")).alias(\"DIFF\"))\n    .with_columns((pl.col(\"DIFF\") / pl.col(\"LAGGED_VALUE\")).alias(\"PDIFF\"))\n    .select(\n        pl.col(\"Industry\"),\n        cs.matches(\"Labour force characteristics\"),\n        pl.col(\"DATE_YMD\"),\n        pl.col(\"YEAR\"),\n        pl.col(\"MONTH\"),\n        cs.matches(\"VALUE\"),\n        cs.matches(\"DIFF\"),\n    )\n    .sort([\"Industry\", \"YEAR\", \"MONTH\", \"PDIFF\"])\n)\nlabour_processed.glimpse()\n\nRows: 12252\nColumns: 8\n$ Industry      &lt;str&gt; 'Accommodation and food services [72]', 'Accommodation and food services [72]', 'Accommodation and food services [72]', 'Accommodation and food services [72]', 'Accommodation and food services [72]', 'Accommodation and food services [72]', 'Accommodation and food services [72]', 'Accommodation and food services [72]', 'Accommodation and food services [72]', 'Accommodation and food services [72]'\n$ DATE_YMD     &lt;date&gt; 1976-01-01, 1976-02-01, 1976-03-01, 1976-04-01, 1976-05-01, 1976-06-01, 1976-07-01, 1976-08-01, 1976-09-01, 1976-10-01\n$ YEAR          &lt;i32&gt; 1976, 1976, 1976, 1976, 1976, 1976, 1976, 1976, 1976, 1976\n$ MONTH         &lt;i32&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n$ VALUE         &lt;f64&gt; 391.9, 395.1, 399.7, 399.7, 407.7, 411.6, 417.6, 423.7, 423.5, 428.9\n$ LAGGED_VALUE  &lt;f64&gt; None, 391.9, 395.1, 399.7, 399.7, 407.7, 411.6, 417.6, 423.7, 423.5\n$ DIFF          &lt;f64&gt; None, 3.2000000000000455, 4.599999999999966, 0.0, 8.0, 3.900000000000034, 6.0, 6.099999999999966, -0.19999999999998863, 5.399999999999977\n$ PDIFF         &lt;f64&gt; None, 0.008165348303138672, 0.011642622120981943, 0.0, 0.020015011258443835, 0.009565857247976537, 0.014577259475218658, 0.014607279693486507, -0.0004720320981826496, 0.012750885478158152",
    "crumbs": [
      "Processing StatCan Data"
    ]
  },
  {
    "objectID": "01_develop_data_processing.html#signed-centered-rank",
    "href": "01_develop_data_processing.html#signed-centered-rank",
    "title": "Processing StatCan Data",
    "section": "Signed Centered Rank",
    "text": "Signed Centered Rank\nNow we can compute the signed centered rank.\nDefine centered_rank_expr function which takes a polars series and returns an expression, meaning it can be used in a polars with_columns call, which is nice because it can take advantage of polars lazy-evaluation optimization.\nBelow is the definition and a test-case.\n\ndef centered_rank_expr(col):\n    \"\"\"\n    - Largest negative value gets rank -1\n    - Smallest positive value gets rank +1\n    - Zero gets rank 0\n    \"\"\"\n    return (\n        pl.when(col &lt; 0)\n        .then(\n            # minus the total # of -ve values\n            (col.rank(method=\"ordinal\", descending=True) * -1) + (col &gt; 0).sum()\n        )\n        .when(col == 0)\n        .then(pl.lit(0))\n        .when(col &gt; 0)\n        .then(col.rank(method=\"ordinal\") - (col &lt; 0).sum())\n        .otherwise(pl.lit(None))\n    )\n\n# test it on this subset of data\ntest_series = (\n    # .filter(pl.col(\"Labour force characteristics\") == \"Employment\")\n    labour_processed\n    .with_columns(pl.col(\"PDIFF\").round(decimals=4))\n    .filter(pl.col(\"YEAR\") == 2025, pl.col(\"MONTH\") == 1)\n    .select(pl.col(\"PDIFF\"))\n    .sample(n=10, seed=1)\n    .select(\"PDIFF\")\n)\n\ntest_series.with_columns(centered_rank_expr(pl.col(\"PDIFF\")).alias(\"rank\")).sort(\n    \"PDIFF\"\n)\n\n\nshape: (10, 2)\n\n\n\nPDIFF\nrank\n\n\nf64\ni64\n\n\n\n\n-0.0336\n-5\n\n\n-0.0207\n-4\n\n\n-0.0177\n-3\n\n\n-0.0101\n-2\n\n\n-0.003\n-1\n\n\n0.0006\n1\n\n\n0.0109\n2\n\n\n0.0122\n3\n\n\n0.0179\n4\n\n\n0.044\n5\n\n\n\n\n\n\nLooks good, so now we can apply to the data:\n\nlabour_processed = labour_processed.with_columns(\n    centered_rank_across_industry=centered_rank_expr(pl.col(\"PDIFF\")).over(\n        [\"YEAR\", \"MONTH\"]\n    )\n)\nlabour_processed.glimpse()\n\nRows: 12252\nColumns: 9\n$ Industry                       &lt;str&gt; 'Accommodation and food services [72]', 'Accommodation and food services [72]', 'Accommodation and food services [72]', 'Accommodation and food services [72]', 'Accommodation and food services [72]', 'Accommodation and food services [72]', 'Accommodation and food services [72]', 'Accommodation and food services [72]', 'Accommodation and food services [72]', 'Accommodation and food services [72]'\n$ DATE_YMD                      &lt;date&gt; 1976-01-01, 1976-02-01, 1976-03-01, 1976-04-01, 1976-05-01, 1976-06-01, 1976-07-01, 1976-08-01, 1976-09-01, 1976-10-01\n$ YEAR                           &lt;i32&gt; 1976, 1976, 1976, 1976, 1976, 1976, 1976, 1976, 1976, 1976\n$ MONTH                          &lt;i32&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n$ VALUE                          &lt;f64&gt; 391.9, 395.1, 399.7, 399.7, 407.7, 411.6, 417.6, 423.7, 423.5, 428.9\n$ LAGGED_VALUE                   &lt;f64&gt; None, 391.9, 395.1, 399.7, 399.7, 407.7, 411.6, 417.6, 423.7, 423.5\n$ DIFF                           &lt;f64&gt; None, 3.2000000000000455, 4.599999999999966, 0.0, 8.0, 3.900000000000034, 6.0, 6.099999999999966, -0.19999999999998863, 5.399999999999977\n$ PDIFF                          &lt;f64&gt; None, 0.008165348303138672, 0.011642622120981943, 0.0, 0.020015011258443835, 0.009565857247976537, 0.014577259475218658, 0.014607279693486507, -0.0004720320981826496, 0.012750885478158152\n$ centered_rank_across_industry  &lt;i64&gt; None, 8, 11, 0, 8, 8, 9, 8, -1, 5\n\n\n\nCheck output visually for 1 year 1 month\n\n# check 1 year 1 month\n(\n    labour_processed\n    .with_columns(pl.col(\"PDIFF\").round(decimals=4))\n    .filter(pl.col(\"YEAR\") == 2025)\n    .sort([\"YEAR\", \"MONTH\", \"PDIFF\"])\n    .select([\"YEAR\", \"MONTH\", \"Industry\", \"VALUE\", \"DIFF\", \"PDIFF\", cs.matches(\"rank\")])\n)\n\n\nshape: (168, 7)\n\n\n\nYEAR\nMONTH\nIndustry\nVALUE\nDIFF\nPDIFF\ncentered_rank_across_industry\n\n\ni32\ni32\nstr\nf64\nf64\nf64\ni64\n\n\n\n\n2025\n1\n\"Wholesale trade [41]\"\n689.4\n-24.0\n-0.0336\n-8\n\n\n2025\n1\n\"Utilities [22]\"\n155.8\n-3.3\n-0.0207\n-7\n\n\n2025\n1\n\"Other services (except public …\n771.0\n-13.9\n-0.0177\n-6\n\n\n2025\n1\n\"Forestry, fishing, mining, qua…\n337.1\n-5.6\n-0.0163\n-5\n\n\n2025\n1\n\"Business, building and other s…\n726.4\n-7.4\n-0.0101\n-4\n\n\n…\n…\n…\n…\n…\n…\n…\n\n\n2025\n8\n\"Accommodation and food service…\n1177.1\n9.2\n0.0079\n5\n\n\n2025\n8\n\"Construction [23]\"\n1636.3\n17.1\n0.0106\n6\n\n\n2025\n8\n\"Agriculture [111-112, 1100, 11…\n217.7\n4.8\n0.0225\n7\n\n\n2025\n8\n\"Utilities [22]\"\n163.5\n4.7\n0.0296\n8\n\n\n2025\n8\n\"Wholesale trade [41]\"\n731.1\n27.6\n0.0392\n9",
    "crumbs": [
      "Processing StatCan Data"
    ]
  }
]